[{"path":"https://r-world-devs.github.io/GitAI/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 GitAI authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://r-world-devs.github.io/GitAI/articles/building-shiny-app-chatbot.html","id":"demo-app-specs","dir":"Articles","previous_headings":"","what":"Demo App Specs","title":"Building simple Shiny app with a chatbot","text":"vignette show build simple Shiny app chat bot, like one: GitAI-demo  can see, demo app chatbot answers based results processed content multiple git repositories. build app: scanned 800+ repositories multiple public GitHub organizations: r-world-devs, openpharma, pharmaverse, tidymodels, r-lib, rstudio, tidyverse, insightsengineering. repositories scanned following files types: DESCRIPTION, *.md, *.Rmd, includes files like README.md R package vignettes. used simple cheap LLM gpt-4o-mini OpenAI. embeddings use multilingual-e5-large embedding model Pinecone well vector database 1024 dimensions. overall one-time cost processing 800+ repositories less $1 setup (yes, one USD!). Even impressive results can achieved powerful LLMs, higher-dimensional embeddings.","code":""},{"path":"https://r-world-devs.github.io/GitAI/articles/building-shiny-app-chatbot.html","id":"processing-git-repositories-with-llm","dir":"Articles","previous_headings":"Demo App Specs","what":"Processing Git repositories with LLM","title":"Building simple Shiny app with a chatbot","text":"First, need set GitAI project call my_project. also setting Pinecone database default provided LLM openai gpt-4o-mini model. Next, need provide list repositories groups repositories want scan. also define files types want process within repository (present). Next need define prompt LLM. might improved multiple iterations get best possible results. Next step optional, hopefully won’t needed future. changes default chat_perform_value function ellmer package make robust LLM provider API errors. don’t get timeout errors, can safely ignore step. Now can process repositories single function call. defined vector database, result written . case error can just repeat function call. repository content hasn’t changed, results already database, function skip processing repository move next one.","code":"library(GitAI) my_project <- initialize_project(\"gitai-demo\") |>   set_database(     provider  = \"Pinecone\",      index     = \"gitai\"   ) |>   set_llm(seed = 1014, api_args = list(temperature = 0)) my_project <- my_project |>   set_github_repos(     repos = c(       \"r-world-devs/GitStats\",        \"r-world-devs/GitAI\",        \"r-world-devs/cohortBuilder\",        \"r-world-devs/shinyCohortBuilder\",       \"r-world-devs/shinyQueryBuilder\",        \"r-world-devs/queryBuilder\",        \"r-world-devs/shinyGizmo\",        \"r-world-devs/shinyTimelines\",       \"openpharma/DataFakeR\"     ),     orgs = c(       \"insightsengineering\",       \"openpharma\",       \"pharmaverse\",       \"tidymodels\",       \"r-lib\",       \"rstudio\",       \"tidyverse\"     )   ) |>   add_files(c(     \"DESCRIPTION\",     \"*.md\",     \"*.Rmd\"   )) my_project <- my_project |>   set_prompt(r\"(     Write up to ten paragraphs of summary for a project based on given input.     Be precise and to the point in your answers.     Mention core functionality and all main features of the project.     If available, mention brifly the technology used in the project      (like R, Python, etc).     If available, mention brifly if a project is an R package, shiny app,      or other type of tool.   )\") ellmer:::chat_perform_value custom_function <- function(provider, req) {    req <- req |>      httr2::req_timeout(60 * 10) |>     httr2::req_retry(       max_tries = 10,       retry_on_failure = TRUE     )       req |>      httr2::req_perform() |>      httr2::resp_body_json() } unlockBinding(\"chat_perform_value\", asNamespace(\"ellmer\")) assign(\"chat_perform_value\", custom_function, envir = asNamespace(\"ellmer\")) lockBinding(\"chat_perform_value\", asNamespace(\"ellmer\")) results <- process_repos(my_project)"},{"path":"https://r-world-devs.github.io/GitAI/articles/building-shiny-app-chatbot.html","id":"semantic-search-queries","dir":"Articles","previous_headings":"","what":"Semantic search queries","title":"Building simple Shiny app with a chatbot","text":"repositories processed stored vector database, can use semantic search queries find results. can see need define project, database, LLM.","code":"my_project <- initialize_project(\"gitai-demo\") |>   set_database(     provider  = \"Pinecone\",      index     = \"gitai\"   ) |>   set_llm(seed = 1014, api_args = list(temperature = 0))  my_project |>    find_records(     \"How can I create fake data based on SQL tables?\",      top_k = 1   ) |>   purrr::walk(~ cat(     .x$metadata$text |>        stringr::str_sub(end = 1000) |>        stringr::str_wrap(width = 80) |>        paste0(\"...\")   ))  #> DataFakeR is an R package designed to generate fake data for relational #> databases while preserving the structure and constraints of the original data. #> The package is particularly useful for developers and data scientists who need #> to create realistic datasets for testing, development, or demonstration purposes #> without exposing sensitive information. The current version, 0.1.3, includes #> several enhancements and bug fixes, making it a robust tool for data simulation. #> The core functionality of DataFakeR revolves around its ability to read a #> schema description in YAML format, which defines the structure of the database #> tables, including columns, data types, constraints, and relationships. Users can #> source this schema from an existing database or define it manually. The package #> supports various data types, including character, numeric, integer, logical, #> and date, allowing for a wide range of data generation scenarios. One of the #> standout features of DataFakeR is its support for determinist..."},{"path":"https://r-world-devs.github.io/GitAI/articles/building-shiny-app-chatbot.html","id":"shiny-chatbot-with-rag","dir":"Articles","previous_headings":"","what":"Shiny chatbot with RAG","title":"Building simple Shiny app with a chatbot","text":"Now ’s time building shiny app. app use shinychat chatbot ellmer answering user questions. providing answer user, prompt augmented top k results semantic search.","code":"library(shiny) library(shinychat) library(GitAI)  gitai <- initialize_project(\"gitai-demo\") |>   set_database(index = \"gitai\") |>    set_llm(seed = 1014, api_args = list(temperature = 0)) |>    set_prompt(r\"(     As a helpful assistant, answer user question      using only the provided input.      Use only provided with the query known input      that is most relevent to the user's query.     Do not use any other information      apart from the input provided with the query.     Be concise but provide all important information.     Also awalys provide link to mentioned git repositories      with visible full URL for example: https://github.com/some_repository.      Do not mask it with any other text.     )\")      ui <- bslib::page_fluid(   bslib::layout_sidebar(     sidebar = shiny::sliderInput(       \"top_k\",        \"Use top K results\",        step = 1,       min = 1,        max = 10,        value = 5     ),      chat_ui(\"chat\")   ) )  server <- function(input, output, session) {    user_chatbot <- gitai$llm$clone()    shiny::observeEvent(input$chat_user_input, {      query <- input$chat_user_input      stream <- user_chatbot$stream_async(       paste(         \"User query:\", query, \"\\n\\n\",         \"Known input provided for the answer:\\n\\n\",          gitai$db$find_records(query = query, top_k = input$top_k)       )     )     chat_append(\"chat\", stream)   }) }  shinyApp(ui, server)"},{"path":"https://r-world-devs.github.io/GitAI/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kamil Wais. Author, maintainer. Krystian Igras. Author. Maciej Banas. Author.","code":""},{"path":"https://r-world-devs.github.io/GitAI/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Wais K, Igras K, Banas M (2025). GitAI: Extracts Knowledge Git Repositories. R package version 0.0.0.9018.","code":"@Manual{,   title = {GitAI: Extracts Knowledge From Git Repositories},   author = {Kamil Wais and Krystian Igras and Maciej Banas},   year = {2025},   note = {R package version 0.0.0.9018}, }"},{"path":"https://r-world-devs.github.io/GitAI/index.html","id":"gitai-","dir":"","previous_headings":"","what":"Extracts Knowledge From Git Repositories","title":"Extracts Knowledge From Git Repositories","text":"goal GitAI extract knowledge Git repositories use AI/LLM (Large Language Models).","code":""},{"path":"https://r-world-devs.github.io/GitAI/index.html","id":"motivation","dir":"","previous_headings":"","what":"Motivation","title":"Extracts Knowledge From Git Repositories","text":"Large organizations need deal massive number git repositories (internal external). repositories can hosted different platforms (like GitHub GitLab). difficult even impossible review repositories manually, especially one needs perform exploratory search, knowing exact keywords used. reusability knowledge (code) hidden repositories constant challenge.","code":""},{"path":"https://r-world-devs.github.io/GitAI/index.html","id":"solution","dir":"","previous_headings":"","what":"Solution","title":"Extracts Knowledge From Git Repositories","text":"propose GitAI framework written R. applicable multiple use cases related extracting knowledge Git repositories. time, infrastructure agnostic. designed work different backends, LLMs, embeddings models, vector databases. Adapting particular backends may need implementation new classes, core functionality stays .","code":""},{"path":"https://r-world-devs.github.io/GitAI/index.html","id":"workflow","dir":"","previous_headings":"","what":"Workflow","title":"Extracts Knowledge From Git Repositories","text":"Typical GitAI workflow looks like : Set project scope (Git repositories). Select content type interest (files file types). Choose LLM backend. Define LLM prompts. (Optional) Choose embedding model vector database provider. (Optional) vector database setup, results stored . (Optional) results stored vector database, can searched using semantic search used part RAG (Retrieval Augmented Generation) prompt.","code":""},{"path":"https://r-world-devs.github.io/GitAI/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Extracts Knowledge From Git Repositories","text":"can install development version GitAI GitHub :","code":"# install.packages(\"pak\") pak::pak(\"r-world-devs/GitAI\")"},{"path":"https://r-world-devs.github.io/GitAI/index.html","id":"simplified-example-without-vector-database-usage","dir":"","previous_headings":"","what":"Simplified example (without vector database usage)","title":"Extracts Knowledge From Git Repositories","text":"Let’s set project fascinating_project extract summaries content README.md files selected git repositories. Now, let’s get results print .","code":"library(GitAI) options(ellmer_timeout_s = 120) verbose_off() my_project <- initialize_project(\"fascinating_project\") |>   set_github_repos(     repos = c(       \"r-world-devs/GitStats\",        \"r-world-devs/GitAI\",        \"openpharma/DataFakeR\"     )   ) |>   add_files(files = \"README.md\") |>   set_llm() |>   set_prompt(\"Write one-sentence summary for a project based on given input.\") results <- process_repos(my_project)  purrr::walk(results, function(result) {   result$text |> stringr::str_wrap(width = 80) |> cat(\"\\n\\n\") }) #> GitStats is an experimental R package that facilitates the extraction #> and analysis of git data from GitHub and GitLab, providing insights into #> repositories, commits, users, and R package usage in a structured format.  #>  #> GitAI is an R package that leverages AI and Large Language Models to extract #> insights from GitHub or GitLab repositories, allowing users to define project #> scopes, select relevant content, and process repositories efficiently in a #> tidyverse-compliant manner.  #>  #> DataFakeR is an R package that enables users to generate synthetic datasets #> while maintaining specified assumptions about the original data structure, #> facilitating data simulation for testing and analysis."},{"path":"https://r-world-devs.github.io/GitAI/index.html","id":"see-also","dir":"","previous_headings":"","what":"See also","title":"Extracts Knowledge From Git Repositories","text":"GitAI uses hood GitStats R package. want use directly pulling git data, check : https://r-world-devs.github.io/GitStats/","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/GitAI-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Derive knowledge from GitHub or GitLab repositories with the use of AI/LLM — GitAI-package","title":"Derive knowledge from GitHub or GitLab repositories with the use of AI/LLM — GitAI-package","text":"Scan multiple Git repositories, pull specified files content process Large Language Models. can summarize content specific way, extract information data, find answers questions repositories. output can stored vector database used semantic search part RAG (Retrieval Augmented Generation) prompt.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/GitAI-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Derive knowledge from GitHub or GitLab repositories with the use of AI/LLM — GitAI-package","text":"Maintainer: Kamil Wais kamil.wais@gmail.com Authors: Krystian Igras krystian8207@gmail.com Maciej Banas banasmaciek@gmail.com","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/add_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Add files to GitAI object. — add_files","title":"Add files to GitAI object. — add_files","text":"Add files GitAI object.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/add_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add files to GitAI object. — add_files","text":"","code":"add_files(gitai, files)"},{"path":"https://r-world-devs.github.io/GitAI/reference/add_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add files to GitAI object. — add_files","text":"gitai GitAI object. files character vector file paths. May defined regular expression.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/add_files.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add files to GitAI object. — add_files","text":"GitAI object.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/find_records.html","id":null,"dir":"Reference","previous_headings":"","what":"Finding top K records in a vector database. — find_records","title":"Finding top K records in a vector database. — find_records","text":"Finding top K records vector database.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/find_records.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finding top K records in a vector database. — find_records","text":"","code":"find_records(gitai, query, top_k = 1, verbose = is_verbose())"},{"path":"https://r-world-devs.github.io/GitAI/reference/find_records.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finding top K records in a vector database. — find_records","text":"gitai GitAI object. query character, user query. top_k numeric, number top K records return. verbose logical. FALSE getting additional diagnostic messages.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/initialize_project.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize a GitAI project. — initialize_project","title":"Initialize a GitAI project. — initialize_project","text":"Initialize GitAI project.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/initialize_project.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize a GitAI project. — initialize_project","text":"","code":"initialize_project(project_id)"},{"path":"https://r-world-devs.github.io/GitAI/reference/initialize_project.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize a GitAI project. — initialize_project","text":"project_id character, ID project.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/initialize_project.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize a GitAI project. — initialize_project","text":"GitAI object.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/is_verbose.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks if GitAI is verbose — is_verbose","title":"Checks if GitAI is verbose — is_verbose","text":"function searches GITAI_VERBOSE environmental variable tries read value logical.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/is_verbose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks if GitAI is verbose — is_verbose","text":"","code":"is_verbose()"},{"path":"https://r-world-devs.github.io/GitAI/reference/is_verbose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks if GitAI is verbose — is_verbose","text":"logical. Default TRUE.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/missing_deps_note_fix.html","id":null,"dir":"Reference","previous_headings":"","what":"This function is meant to fix 'Namespaces in Imports field not imported from:' R check note. The note shows up when namespace is used to create package object (not function) or within file marked at '.Rbuildignore' file. — missing_deps_note_fix","title":"This function is meant to fix 'Namespaces in Imports field not imported from:' R check note. The note shows up when namespace is used to create package object (not function) or within file marked at '.Rbuildignore' file. — missing_deps_note_fix","text":"function meant fix 'Namespaces Imports field imported :' R check note. note shows namespace used create package object (function) within file marked '.Rbuildignore' file.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/missing_deps_note_fix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function is meant to fix 'Namespaces in Imports field not imported from:' R check note. The note shows up when namespace is used to create package object (not function) or within file marked at '.Rbuildignore' file. — missing_deps_note_fix","text":"","code":"missing_deps_note_fix()"},{"path":"https://r-world-devs.github.io/GitAI/reference/process_repos.html","id":null,"dir":"Reference","previous_headings":"","what":"Run LLM on GitAI repositories content — process_repos","title":"Run LLM on GitAI repositories content — process_repos","text":"Run LLM GitAI repositories content","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/process_repos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run LLM on GitAI repositories content — process_repos","text":"","code":"process_repos(gitai, depth = 1, verbose = is_verbose())"},{"path":"https://r-world-devs.github.io/GitAI/reference/process_repos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run LLM on GitAI repositories content — process_repos","text":"gitai GitAI object. depth numeric, maximum depth folders process. verbose logical. FALSE getting additional diagnostic messages.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/process_repos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run LLM on GitAI repositories content — process_repos","text":"list.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/set_database.html","id":null,"dir":"Reference","previous_headings":"","what":"Setting database in GitAI object. — set_database","title":"Setting database in GitAI object. — set_database","text":"Setting database GitAI object.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/set_database.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setting database in GitAI object. — set_database","text":"","code":"set_database(gitai, provider = \"Pinecone\", ...)"},{"path":"https://r-world-devs.github.io/GitAI/reference/set_database.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setting database in GitAI object. — set_database","text":"gitai GitAI object. provider string. Name database provider. ... Additional arguments pass database provider constructor.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/set_github_repos.html","id":null,"dir":"Reference","previous_headings":"","what":"Set GitHub repositories in GitAI object. — set_github_repos","title":"Set GitHub repositories in GitAI object. — set_github_repos","text":"Set GitHub repositories GitAI object.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/set_github_repos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set GitHub repositories in GitAI object. — set_github_repos","text":"","code":"set_github_repos(gitai, ... = ..., verbose = is_verbose())"},{"path":"https://r-world-devs.github.io/GitAI/reference/set_github_repos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set GitHub repositories in GitAI object. — set_github_repos","text":"gitai GitAI object. ... Parameters pass set_github_host function. verbose logical. FALSE getting additional diagnostic messages.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/set_github_repos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set GitHub repositories in GitAI object. — set_github_repos","text":"GitAI object.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/set_gitlab_repos.html","id":null,"dir":"Reference","previous_headings":"","what":"Set GitLab repositories in GitAI object. — set_gitlab_repos","title":"Set GitLab repositories in GitAI object. — set_gitlab_repos","text":"Set GitLab repositories GitAI object.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/set_gitlab_repos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set GitLab repositories in GitAI object. — set_gitlab_repos","text":"","code":"set_gitlab_repos(gitai, ... = ..., verbose = is_verbose())"},{"path":"https://r-world-devs.github.io/GitAI/reference/set_gitlab_repos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set GitLab repositories in GitAI object. — set_gitlab_repos","text":"gitai GitAI object. ... Parameters pass set_gitlab_host function. verbose logical. FALSE getting additional diagnostic messages.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/set_gitlab_repos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set GitLab repositories in GitAI object. — set_gitlab_repos","text":"GitAI object.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/set_llm.html","id":null,"dir":"Reference","previous_headings":"","what":"Set Large Language Model in GitAI object. — set_llm","title":"Set Large Language Model in GitAI object. — set_llm","text":"Set Large Language Model GitAI object.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/set_llm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set Large Language Model in GitAI object. — set_llm","text":"","code":"set_llm(gitai, provider = \"openai\", ...)  get_llm_defaults(provider)"},{"path":"https://r-world-devs.github.io/GitAI/reference/set_llm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set Large Language Model in GitAI object. — set_llm","text":"gitai GitAI object. provider Name LLM provider, string. Results setting LLM using ellmer::chat_<provider> function. ... arguments pass corresponding ellmer::chat_<provider> function. Please use get_llm_defaults get default model arguments.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/set_llm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set Large Language Model in GitAI object. — set_llm","text":"GitAI object.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/set_prompt.html","id":null,"dir":"Reference","previous_headings":"","what":"Set prompt. — set_prompt","title":"Set prompt. — set_prompt","text":"Set prompt.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/set_prompt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set prompt. — set_prompt","text":"","code":"set_prompt(gitai, system_prompt)"},{"path":"https://r-world-devs.github.io/GitAI/reference/set_prompt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set prompt. — set_prompt","text":"gitai GitAI object. system_prompt system prompt.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/set_prompt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set prompt. — set_prompt","text":"GitAI object.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/verbose_off.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets GitAI to be quiet. — verbose_off","title":"Sets GitAI to be quiet. — verbose_off","text":"function sets GITAI_VERBOSE environmental variable FALSE.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/verbose_off.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets GitAI to be quiet. — verbose_off","text":"","code":"verbose_off()"},{"path":"https://r-world-devs.github.io/GitAI/reference/verbose_on.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets GitAI to be verbose — verbose_on","title":"Sets GitAI to be verbose — verbose_on","text":"function sets GITAI_VERBOSE environmental variable TRUE.","code":""},{"path":"https://r-world-devs.github.io/GitAI/reference/verbose_on.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets GitAI to be verbose — verbose_on","text":"","code":"verbose_on()"}]
